# Cloud Z CP Monitoring component for controlplane cluster

## Component summary

| Component                     | Chart Version | App Version | Image
| ---                           | ---           | ---         | ---
| cortex                        | 0.1.2         | 1.1.0       | quay.io/cortexproject/cortex:v1.1.0
| postgresql for cortex-configs | 8.10.11       | 11.8.0      | bitnami/postgresql:11.8.0-debian-10-r33
| cortex-gateway                | N/A           | 1.0.1       | zodiac12k/cortex-gateway:v1.0.1
| consul                        | 0.22.0        | 1.8.0       | consul:1.8.0
| memcached                     | 3.2.3         | 1.5.20      | memcached:1.5.20
| grafana                       | 5.1.4         | 7.0.3       | grafana/grafana:7.0.3
| postgresql for grafana        | 8.10.11       | 11.8.0      | bitnami/postgresql:11.8.0-debian-10-r33

## Installation

### Prerequisite

* Helm 3

### Cortex

Data Centralization, Long Term Storage, Multi Tenancy for prometheus metrics

#### Install consul

key-value(KV) store for [high availability tracker](https://cortexmetrics.io/docs/architecture/#high-availability-tracker) and [hash ring](https://cortexmetrics.io/docs/architecture/#the-hash-ring)

```shell script
helm repo add hashicorp https://helm.releases.hashicorp.com
helm install consul hashicorp/consul \
--set global.name=consul \
--set server.storageClass=ebs-gp2
```

#### Install postgresql for cortex-configs db

for EKS
```shell script
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install cortex-configs-db bitnami/postgresql \
--set postgresqlDatabase=configs \
--set persistence.storageClass=ebs-gp2
```

#### Create S3 for cortex backend storage

* bucket_name: <CONTROLPLANE_CLUSTER_NAME>-cortex-tsdb

#### Install cortex with helm 3

Move to cortex helm chart repository

for EKS
```shell script
helm install cortex . -f cortex/values-eks.yaml \
--set ingress.annotations."kubernetes\.io/ingress\.class"=nginx \
--set ingress.hosts[0].host=cortex.mcm-dev.cloudzcp.com \
--set ingress.tls[0].secretName=cloudzcp-com-cert \
--set ingress.tls[0].hosts[0]=cortex.mcm-dev.cloudzcp.com
```

#### Deploy cortex gateway

Please Generate SHA-512 bit key. You can generate in https://keygen.io/

```shell script
kubectl create secret generic cortex-jwt-secret --from-literal jwt_secret=xxx
```

```shell script
kubectl apply -f cortex/cortex-gateway-deployment.yaml
kubectl apply -f cortex/cortex-gateway-service.yaml
```

#### Add alert rules to each tenant

```shell script
curl -X POST -H 'Authorization: Bearer xxx'  \
--data '{
       "rule_format_version": "2",
       "alertmanager_config": "global:\n  # ResolveTimeout is the time after which an alert is declared resolved\n  # if it has not been updated.\n  resolve_timeout: 5m\n\n  # The smarthost and SMTP sender used for mail notifications.\n  smtp_smarthost: 'smtp.sendgrid.net:587'\n  smtp_from: 'alertmanager@zcp.com'\n  smtp_auth_username: 'foo@bar.com'\n  smtp_auth_password: 'barfoo'\n  smtp_auth_secret: 'foobar'\n  smtp_require_tls: true\n\n  slack_api_url: 'https://global.slack_api_url'\n  hipchat_auth_token: '1234556789'\n  hipchat_api_url: 'https://hipchat.foobar.org/'\n\n# The root route on which each incoming alert enters.\nroute:\n\n  # The labels by which incoming alerts are grouped together. For example,\n  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would\n  # be batched into a single group.\n\n  group_by: ['alertname', 'cluster', 'priority', 'product']\n\n  # When a new group of alerts is created by an incoming alert, wait at\n  # least 'group_wait' to send the initial notification.\n  # This way ensures that you get multiple alerts for the same group that start\n  # firing shortly after another are batched together on the first\n  # notification.\n\n  group_wait: 30s\n\n  # When the first notification was sent, wait 'group_interval' to send a batch\n  # of new alerts that started firing for that group.\n\n  group_interval: 5m\n\n  # If an alert has successfully been sent, wait 'repeat_interval' to\n  # resend them.\n\n  repeat_interval: 60m\n\n  # A default receiver\n\n  # If an alert isn't caught by a route, send it to default.\n  receiver: default\n\n  # All the above attributes are inherited by all child routes and can\n  # overwritten on each.\n\n  # The child route trees.\n  routes:\n  - receiver: default\n    continue: true\n\nreceivers:\n- name: 'default'\n  webhook_configs:\n  - url: https://api.cloudzcp.io/alert/webhook/alertmanager\n    send_resolved: true\n    http_config:\n      basic_auth:\n        username: alertmanager\n        password: Alertmanager!23$\n",
       "rules_files": {
           "alertmanager.rules": "groups:\n- name: alertmanager.rules\n  rules:\n  - alert: AlertmanagerFailedReload\n    expr: alertmanager_config_last_reload_successful == 0\n    for: 10m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P4\n    annotations:\n      description: Reloading Alertmanager's configuration has failed\n      summary: Alertmanager configuration reload has failed",
           "kube-apiserver.rules": "groups:\n- name: kube-apiserver.rules\n  rules:\n  - alert: APIServerDown\n    expr: up{job=\"kubernetes-apiservers\"} == 0\n    for: 5m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: API server unreachable\n      description: Prometheus failed to scrape API server\n  - alert: APIServerErrorsHigh\n    expr: sum(rate(apiserver_request_count{code=~\"^(?:5..)$\"}[5m])) / sum(rate(apiserver_request_count[5m])) * 100 > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: API server Errors High\n      description: \"API server returns errors for {{$value}}% of requests summary: API server request errors\"\n  - alert: APIServerLatencyHigh\n    expr: avg(apiserver_request_latencies_sum / apiserver_request_latencies_count) / 1000000 > 2000\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: API server Latency High\n      description: \"API server latency High above 2s (current value: {{ $value }}ms\"",
           "kube-state-metrics.rules": "groups:\n- name: kube-state-metrics.rules\n  rules:\n  - record: kube_node_status_condition_ready\n    expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"}\n  - alert: K8SManagementNodeNotReady\n    expr: kube_node_labels{dedicated=\"management\"} and on (node) kube_node_status_condition_ready == 0\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) status is NotReady\"\n      description: \"The kubelet on {{$labels.node}} has not checked in with the API, or has set itself to NotReady, for more than 2m.\"\n  - alert: K8SLoggingNodeNotReady\n    expr: kube_node_labels{dedicated=\"logging\"} and on (node) kube_node_status_condition_ready == 0\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) status is NotReady\"\n      description: \"The kubelet on {{$labels.node}} has not checked in with the API, or has set itself to NotReady, for more than 2m.\"\n  - alert: K8SWorkerNodeNotReady\n    expr: kube_node_labels{dedicated=~\"worker|ha-worker\"} and on (node) kube_node_status_condition_ready == 0\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) status is NotReady\"\n      description: \"The kubelet on {{$labels.node}} has not checked in with the API, or has set itself to NotReady, for more than 2m.\"\n  - alert: K8SEdgeNodeNotReady\n    expr: kube_node_labels{dedicated=\"edge\"} and on (node) kube_node_status_condition_ready == 0\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) status is NotReady\"\n      description: \"The kubelet on {{$labels.node}} has not checked in with the API, or has set itself to NotReady, for more than 2m.\"\n  - alert: K8SZDBNodeNotReady\n    expr: kube_node_labels{dedicated=\"zdb\"} and on (node) kube_node_status_condition_ready == 0\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) status is NotReady\"\n      description: \"The kubelet on {{$labels.node}} has not checked in with the API, or has set itself to NotReady, for more than 2m.\"\n\n  - record: kube_node_status_condition_out_of_disk\n    expr: kube_node_status_condition{condition=\"OutOfDisk\",status=\"true\"}\n  - alert: K8SManagementNodeOutOfDisk\n    expr: kube_node_labels{dedicated=\"management\"} and on (node) kube_node_status_condition_out_of_disk == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) ran out of disk space.\"\n      description: \"{{$labels.node}} is insufficient free space on the node for adding new pods.\"\n  - alert: K8SLoggingNodeOutOfDisk\n    expr: kube_node_labels{dedicated=\"logging\"} and on (node) kube_node_status_condition_out_of_disk == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) ran out of disk space.\"\n      description: \"{{$labels.node}} is insufficient free space on the node for adding new pods.\"\n  - alert: K8SWorkerNodeOutOfDisk\n    expr: kube_node_labels{dedicated=~\"worker|ha-worker\"} and on (node) kube_node_status_condition_out_of_disk == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) ran out of disk space.\"\n      description: \"{{$labels.node}} is insufficient free space on the node for adding new pods.\"\n  - alert: K8SEdgeNodeOutOfDisk\n    expr: kube_node_labels{dedicated=\"edge\"} and on (node) kube_node_status_condition_out_of_disk == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) ran out of disk space.\"\n      description: \"{{$labels.node}} is insufficient free space on the node for adding new pods.\"\n  - alert: K8SZDBNodeOutOfDisk\n    expr: kube_node_labels{dedicated=\"zdb\"} and on (node) kube_node_status_condition_out_of_disk == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) ran out of disk space.\"\n      description: \"{{$labels.node}} is insufficient free space on the node for adding new pods.\"\n\n  - record: kube_node_status_condition_memory_pressure\n    expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"}\n  - alert: K8SManagementNodeMemoryPressure\n    expr: kube_node_labels{dedicated=\"management\"} and on (node) kube_node_status_condition_memory_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under memory pressure.\"\n      description: \"{{$labels.node}} memory is low.\"\n  - alert: K8SLoggingNodeMemoryPressure\n    expr: kube_node_labels{dedicated=\"logging\"} and on (node) kube_node_status_condition_memory_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under memory pressure.\"\n      description: \"{{$labels.node}} memory is low.\"\n  - alert: K8SWorkerNodeMemoryPressure\n    expr: kube_node_labels{dedicated=~\"worker|ha-worker\"} and on (node) kube_node_status_condition_memory_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under memory pressure.\"\n      description: \"{{$labels.node}} memory is low.\"\n  - alert: K8SEdgeNodeMemoryPressure\n    expr: kube_node_labels{dedicated=\"edge\"} and on (node) kube_node_status_condition_memory_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under memory pressure.\"\n      description: \"{{$labels.node}} memory is low.\"\n  - alert: K8SZDBNodeMemoryPressure\n    expr: kube_node_labels{dedicated=\"zdb\"} and on (node) kube_node_status_condition_memory_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under memory pressure.\"\n      description: \"{{$labels.node}} memory is low.\"\n\n  - record: kube_node_status_condition_pid_pressure\n    expr: kube_node_status_condition{condition=\"PIDPressure\",status=\"true\"}\n  - alert: K8SManagementNodePIDPressure\n    expr: kube_node_labels{dedicated=\"management\"} and on (node) kube_node_status_condition_pid_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under PID pressure.\"\n      description: \"{{$labels.node}} is too many processes on the node.\"\n  - alert: K8SLoggingNodePIDPressure\n    expr: kube_node_labels{dedicated=\"logging\"} and on (node) kube_node_status_condition_pid_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under PID pressure.\"\n      description: \"{{$labels.node}} is too many processes on the node.\"\n  - alert: K8SWorkerNodePIDPressure\n    expr: kube_node_labels{dedicated=~\"worker|ha-worker\"} and on (node) kube_node_status_condition_pid_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under PID pressure.\"\n      description: \"{{$labels.node}} is too many processes on the node.\"\n  - alert: K8SEdgeNodePIDPressure\n    expr: kube_node_labels{dedicated=\"edge\"} and on (node) kube_node_status_condition_pid_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under PID pressure.\"\n      description: \"{{$labels.node}} is too many processes on the node.\"\n  - alert: K8SZDBNodePIDPressure\n    expr: kube_node_labels{dedicated=\"zdb\"} and on (node) kube_node_status_condition_pid_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under PID pressure.\"\n      description: \"{{$labels.node}} is too many processes on the node.\"\n\n  - record: kube_node_status_condition_disk_pressure\n    expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"}\n  - alert: K8SManagementNodeDiskPressure\n    expr: kube_node_labels{dedicated=\"management\"} and on (node) kube_node_status_condition_disk_pressure == 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under disk pressure.\"\n      description: \"{{$labels.node}} disk capacity is low.\"\n  - alert: K8SLoggingNodeDiskPressure\n    expr: kube_node_labels{dedicated=\"logging\"} and on (node) kube_node_status_condition_disk_pressure == 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under disk pressure.\"\n      description: \"{{$labels.node}} disk capacity is low.\"\n  - alert: K8SWorkerNodeDiskPressure\n    expr: kube_node_labels{dedicated=~\"worker|ha-worker\"} and on (node) kube_node_status_condition_disk_pressure == 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under disk pressure.\"\n      description: \"{{$labels.node}} disk capacity is low.\"\n  - alert: K8SEdgeNodeDiskPressure\n    expr: kube_node_labels{dedicated=\"edge\"} and on (node) kube_node_status_condition_disk_pressure == 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under disk pressure.\"\n      description: \"{{$labels.node}} disk capacity is low.\"\n  - alert: K8SZDBNodeDiskPressure\n    expr: kube_node_labels{dedicated=\"zdb\"} and on (node) kube_node_status_condition_disk_pressure == 1\n    for: 2m\n    labels:\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}) is under disk pressure.\"\n      description: \"{{$labels.node}} disk capacity is low.\"\n\n  - alert: PodFrequentlyRestarting\n    expr: increase(kube_pod_container_status_restarts_total[1h]) > 5\n    for: 10m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P5\n    annotations:\n      summary: \"Pod is restarting frequently\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}} is was restarted {{$value}} times within the last hour\"\n  - alert: PodAbnormallyTerminated\n    expr: sum_over_time(kube_pod_container_status_terminated_reason{namespace!~\"kube-system|ibm-system|zcp-system|zdb-system|zdb-managed\",reason!~\"Completed|Error\"}[5m]) > 0\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Pod is abnormally terminated\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is abnormally terminated for a {{$labels.reason}}\"\n  - alert: PodAbnormallyTerminated\n    expr: sum_over_time(kube_pod_container_status_terminated_reason{namespace=~\"kube-system|ibm-system|zcp-system|zdb-system|zdb-managed\",reason!~\"Completed|Error\"}[5m]) > 0\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Pod is abnormally terminated\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is abnormally terminated for a {{$labels.reason}}\"\n  - alert: PodAbnormallyWaiting\n    expr: sum_over_time(kube_pod_container_status_waiting_reason{namespace!~\"kube-system|ibm-system|zcp-system|zdb-system|zdb-managed\",reason!=\"ContainerCreating\"}[5m]) > 0\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Pod is abnormally waiting\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is abnormally waiting for a {{$labels.reason}}\"\n  - alert: PodAbnormallyWaiting\n    expr: sum_over_time(kube_pod_container_status_waiting_reason{namespace=~\"kube-system|ibm-system|zcp-system|zdb-system|zdb-managed\",reason!=\"ContainerCreating\"}[5m]) > 0\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Pod is abnormally waiting\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is abnormally waiting for a {{$labels.reason}}\"\n  - alert: PodErrorTerminated\n    expr: sum_over_time(kube_pod_container_status_terminated_reason{reason=\"Error\"}[5m]) > 0\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P5\n    annotations:\n      summary: \"Pod is terminated for an error\"\n      description: \"Pod {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is abnormally terminated for an Error\"",
           "kubelet.rules": "groups:\n- name: kubelet.rules\n  rules:\n  - alert: K8SKubeletDown\n    expr: absent(up{job=\"kubernetes-nodes-kubelet\"} == 1)\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P4\n    annotations:\n      description: \"Prometheus failed to scrape {{ $labels.instance }} of kubelet.\"\n      summary: \"Kubelet cannot be scraped\"\n  - alert: K8SKubeletTooManyPods\n    expr: kubelet_running_pod_count > 100\n    for: 10m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      description: \"Kubelet {{$labels.instance}} is running {{$value}} pods, close to the limit of 110\"\n      summary: \"Kubelet is close to pod limit\"\n  - alert: PersistentVolumeLowSpace\n    expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100 > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Persistent Volume({{$labels.namespace}}/{{$labels.persistentvolumeclaim}}): Low disk space\"\n      description: \"Persistent Volume({{$labels.namespace}}/{{$labels.persistentvolumeclaim}}): Disk usage is above 80% (current value is: {{$value}})\"\n  - alert: PersistentVolumeLowSpace\n    expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100 > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Persistent Volume({{$labels.namespace}}/{{$labels.persistentvolumeclaim}}): Low disk space\"\n      description: \"Persistent Volume({{$labels.namespace}}/{{$labels.persistentvolumeclaim}}): Disk usage is above 80% (current value is: {{$value}})\"",
           "node.rules": "groups:\n- name: node.rules\n  rules:\n  - alert: NodeExporterDown\n    expr: absent(up{job=\"kubernetes-nodes-exporter\"} == 1)\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: node-exporter cannot be scraped\n      description: Prometheus failed to scrape Node({{$labels.instance}}) for more than 2m\n\n  - record: node_cpu_usage_rate\n    expr: (100 - (avg by(dedicated,instance)(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100))\n  - alert: ManagementNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"management\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 80% (current value is: {{$value}})\"\n  - alert: LoggingNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"logging\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 80% (current value is: {{$value}})\"\n  - alert: WorkerNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=~\"worker|ha-worker\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 80% (current value is: {{$value}})\"\n  - alert: EdgeNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"edge\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 80% (current value is: {{$value}})\"\n  - alert: ZDBNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"zdb\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 80% (current value is: {{$value}})\"\n\n  - alert: ManagementNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"management\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 95% (current value is: {{$value}})\"\n  - alert: LoggingNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"logging\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P2\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 95% (current value is: {{$value}})\"\n  - alert: WorkerNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=~\"worker|ha-worker\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 95% (current value is: {{$value}})\"\n  - alert: EdgeNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"edge\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 95% (current value is: {{$value}})\"\n  - alert: ZDBNodeCPUUsage\n    expr: node_cpu_usage_rate{dedicated=\"zdb\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High CPU usage detected\"\n      description: \"{{$labels.instance}}: CPU usage is above 95% (current value is: {{$value}})\"\n\n  - alert: ManagementNodeLoadAverage5\n    expr: node_load5{dedicated=\"management\"} / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"}) > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High Load Average detected\"\n      description: \"{{$labels.instance}}: Load Average is high (current value is: {{$value}})\"\n  - alert: LoggingNodeLoadAverage5\n    expr: node_load5{dedicated=\"logging\"} / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"}) > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High Load Average detected\"\n      description: \"{{$labels.instance}}: Load Average is high (current value is: {{$value}})\"\n  - alert: WorkerNodeLoadAverage5\n    expr: node_load5{dedicated=~\"worker|ha-worker\"} / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"}) > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High Load Average detected\"\n      description: \"{{$labels.instance}}: Load Average is high (current value is: {{$value}})\"\n  - alert: EdgeNodeLoadAverage5\n    expr: node_load5{dedicated=\"edge\"} / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"}) > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High Load Average detected\"\n      description: \"{{$labels.instance}}: Load Average is high (current value is: {{$value}})\"\n  - alert: ZDBNodeLoadAverage5\n    expr: node_load5{dedicated=\"zdb\"} / count without (cpu, mode) (node_cpu_seconds_total{mode=\"system\"}) > 1\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High Load Average detected\"\n      description: \"{{$labels.instance}}: Load Average is high (current value is: {{$value}})\"\n\n  - record: node_memory_MemUsed_bytes\n    expr: node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes\n  - record: node_memory_MemUsed_percent\n    expr: node_memory_MemUsed_bytes / node_memory_MemTotal_bytes * 100\n  - record: node_memory_MemUnavailable_bytes\n    expr: node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes\n  - record: node_memory_MemUnavailable_percent\n    expr: node_memory_MemUnavailable_bytes / node_memory_MemTotal_bytes * 100\n  - alert: ManagementNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"management\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 80% (current value is: {{$value}})\"\n  - alert: LoggingNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"logging\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 80% (current value is: {{$value}})\"\n  - alert: WorkerNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=~\"worker|ha-worker\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 80% (current value is: {{$value}})\"\n  - alert: EdgeNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"edge\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 80% (current value is: {{$value}})\"\n  - alert: ZDBNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"zdb\"} > 80\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P3\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 80% (current value is: {{$value}})\"\n\n  - alert: ManagementNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"management\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 95% (current value is: {{$value}})\"\n  - alert: LoggingNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"logging\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 95% (current value is: {{$value}})\"\n  - alert: WorkerNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=~\"worker|ha-worker\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 95% (current value is: {{$value}})\"\n  - alert: EdgeNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"edge\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 75% (current value is: {{$value}})\"\n  - alert: ZDBNodeMemoryUsage\n    expr: node_memory_MemUsed_percent{dedicated=\"zdb\"} > 95\n    for: 2m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): High memory usage detected\"\n      description: \"{{$labels.instance}}: Memory usage is above 95% (current value is: {{$value}})\"\n\n  - alert: NodeSwapUsage\n    expr: ((node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) / node_memory_SwapTotal_bytes) * 100 > 75\n    for: 2m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"{{$labels.instance}}: Swap usage detected\"\n      description: \"{{$labels.instance}}: Swap usage usage is above 75% (current value is: {{ $value }})\"\n\n  - record: node_filesystem_used_bytes\n    expr: node_filesystem_size_bytes - node_filesystem_avail_bytes\n  - record: node_filesystem_used_percent\n    expr: node_filesystem_used_bytes / node_filesystem_size_bytes * 100\n  - alert: ManagementNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"management\",mountpoint=\"/\"} > 80\n    for: 30m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 80% (current value is: {{$value}})\"\n  - alert: LoggingNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"logging\",mountpoint=\"/\"} > 80\n    for: 30m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 80% (current value is: {{$value}})\"\n  - alert: WorkerNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=~\"worker|ha-worker\",mountpoint=\"/\"} > 80\n    for: 30m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 80% (current value is: {{$value}})\"\n  - alert: EdgeNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"edge\",mountpoint=\"/\"} > 80\n    for: 30m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 80% (current value is: {{$value}})\"\n  - alert: ZDBNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"zdb\",mountpoint=\"/\"} > 80\n    for: 30m\n    labels:\n      channel: default\n      severity: warning\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 80% (current value is: {{$value}})\"\n\n  - alert: ManagementNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"management\",mountpoint=\"/\"} > 95\n    for: 30m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 95% (current value is: {{$value}})\"\n  - alert: LoggingNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"logging\",mountpoint=\"/\"} > 95\n    for: 30m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 95% (current value is: {{$value}})\"\n  - alert: WorkerNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=~\"worker|ha-worker\",mountpoint=\"/\"} > 95\n    for: 30m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 95% (current value is: {{$value}})\"\n  - alert: EdgeNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"edge\",mountpoint=\"/\"} > 95\n    for: 30m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 95% (current value is: {{$value}})\"\n  - alert: ZDBNodeLowRootDisk\n    expr: node_filesystem_used_percent{dedicated=\"zdb\",mountpoint=\"/\"} > 95\n    for: 30m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P1\n    annotations:\n      summary: \"Node({{$labels.dedicated}}): Low root disk space\"\n      description: \"{{$labels.instance}}: Root disk usage is above 95% (current value is: {{$value}})\"",
           "prometheus.rules": "groups:\n- name: prometheus.rules\n  rules:\n  - alert: PrometheusFailedReload\n    expr: prometheus_config_last_reload_successful == 0\n    for: 10m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: Prometheus configuration reload has failed\n      description: Reloading Prometheus' configuration has failed for {{ $labels.namespace}}/{{ $labels.pod}}.\n  - alert: PrometheusErrorSendingAlerts\n    expr: rate(prometheus_notifications_errors_total[5m]) / rate(prometheus_notifications_sent_total[5m]) > 0.01\n    for: 10m\n    labels:\n      channel: default\n      severity: critical\n      product: zcp-public\n      priority: P4\n    annotations:\n      summary: Errors while sending alerts from Prometheus\n      description: Errors while sending alerts from Prometheus to Alertmanager {{$labels.Alertmanager}}"
       }
   }' \
https://${zcp-cortex-base-url}/api/prom/configs/alertmanager
```

### Grafana

#### Install postgresql for grafana db

```shell script
helm install zcp-monitoring-db bitnami/postgresql \
--set postgresqlDatabase=grafana \
--set persistence.storageClass=ebs-gp2
```

#### Install grafana

Generate JWT from https://jwt.io/

* HEADER
  ```json
  {
    "alg": "HS512",
    "typ": "JWT"
  }
  ```
* PAYLOAD
  ```json
  {
    "tenant_id": "t1"
  }
  ```
* VERIFY SIGNATURE : input your-256-bit-secret above jwt secret generating from https://keygen.io
  ```
  HMACSHA256(
    base64UrlEncode(header) + "." +
    base64UrlEncode(payload),
    your-256-bit-secret
  )
  ```

```shell script
helm repo add stable https://kubernetes-charts.storage.googleapis.com
helm install zcp-monitoring stable/grafana --namespace zcp-system -f values.yaml \
--set ingress.ingress."kubernetes\.io/ingress\.class"=nginx \
--set ingress.hosts[0]=monitoring.mcm-dev.cloudzcp.com \
--set ingress.tls[0].secretName="cloudzcp-com-cert" \
--set ingress.tls[0].hosts[0]=monitoring.mcm-dev.cloudzcp.com \
--set persistence.storageClassName=efs-zcp \
--set persistence.size=5Gi \
--set env.GF_SERVER_DOMAIN=monitoring.mcm-dev.cloudzcp.com \
--set env.GF_AUTH_GENERIC_OAUTH_AUTH_URL=https://iam.mcm-dev.cloudzcp.com/auth/realms/zcp/protocol/openid-connect/auth \
--set "grafana\.ini".database.url=postgres://postgres:oA3TRh8PNr@zcp-monitoring-posgresql-postgresql:5432/grafana \
--set datasources."datasources\.yaml".datasources[0].jsonData.httpHeaderValue1="Bearer eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJ0ZW5hbnRfaWQiOiJza2NjIn0.Yh7te2ZzIPSxEBqNq6k1_PMdk851vttqhsrvdjnrrPJblQSaNnrxqbAYySkYaZC1LmDBGR0N9fcyVsfyt2weug"
```